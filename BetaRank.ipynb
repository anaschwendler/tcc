{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import math\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    numpy = None\n",
    "\n",
    "from sumy.summarizers._summarizer import AbstractSummarizer\n",
    "from sumy._compat import Counter\n",
    "\n",
    "\n",
    "class BetaSummarizer(AbstractSummarizer):\n",
    "    \"\"\"\n",
    "    LexRank: Graph-based Centrality as Salience in Text Summarization\n",
    "    Source: http://tangra.si.umich.edu/~radev/lexrank/lexrank.pdf\n",
    "    \"\"\"\n",
    "    threshold = 0.1\n",
    "    epsilon = 0.1\n",
    "    _stop_words = frozenset()\n",
    "\n",
    "    @property\n",
    "    def stop_words(self):\n",
    "        return self._stop_words\n",
    "\n",
    "    @stop_words.setter\n",
    "    def stop_words(self, words):\n",
    "        self._stop_words = frozenset(map(self.normalize_word, words))\n",
    "\n",
    "    def __call__(self, document, sentences_count):\n",
    "        self._ensure_dependencies_installed()\n",
    "\n",
    "        sentences_words = [self._to_words_set(s) for s in document.sentences]\n",
    "        if not sentences_words:\n",
    "            return tuple()\n",
    "\n",
    "        tf_metrics = self._compute_tf(sentences_words)\n",
    "        idf_metrics = self._compute_idf(sentences_words)\n",
    "\n",
    "        matrix = self._create_matrix(sentences_words, self.threshold, tf_metrics, idf_metrics)\n",
    "        scores = self.power_method(matrix, self.epsilon)\n",
    "        ratings = dict(zip(document.sentences, scores))\n",
    "\n",
    "        return self._get_best_sentences(document.sentences, sentences_count, ratings)\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_dependencies_installed():\n",
    "        if numpy is None:\n",
    "            raise ValueError(\"LexRank summarizer requires NumPy. Please, install it by command 'pip install numpy'.\")\n",
    "\n",
    "    def _to_words_set(self, sentence):\n",
    "        words = map(self.normalize_word, sentence.words)\n",
    "        return [self.stem_word(w) for w in words if w not in self._stop_words]\n",
    "\n",
    "    def _compute_tf(self, sentences):\n",
    "        tf_values = map(Counter, sentences)\n",
    "\n",
    "        tf_metrics = []\n",
    "        for sentence in tf_values:\n",
    "            metrics = {}\n",
    "            max_tf = self._find_tf_max(sentence)\n",
    "\n",
    "            for term, tf in sentence.items():\n",
    "                metrics[term] = tf / max_tf\n",
    "\n",
    "            tf_metrics.append(metrics)\n",
    "\n",
    "        return tf_metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_tf_max(terms):\n",
    "        return max(terms.values()) if terms else 1\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_idf(sentences):\n",
    "        idf_metrics = {}\n",
    "        sentences_count = len(sentences)\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for term in sentence:\n",
    "                if term not in idf_metrics:\n",
    "                    n_j = sum(1 for s in sentences if term in s)\n",
    "                    idf_metrics[term] = math.log(sentences_count / (1 + n_j))\n",
    "\n",
    "        return idf_metrics\n",
    "\n",
    "    def _create_matrix(self, sentences, threshold, tf_metrics, idf_metrics):\n",
    "        \"\"\"\n",
    "        Creates matrix of shape |sentences|×|sentences|.\n",
    "        \"\"\"\n",
    "        # create matrix |sentences|×|sentences| filled with zeroes\n",
    "        sentences_count = len(sentences)\n",
    "        matrix = numpy.zeros((sentences_count, sentences_count))\n",
    "        degrees = numpy.zeros((sentences_count, ))\n",
    "\n",
    "        for row, (sentence1, tf1) in enumerate(zip(sentences, tf_metrics)):\n",
    "            for col, (sentence2, tf2) in enumerate(zip(sentences, tf_metrics)):\n",
    "                matrix[row, col] = compute_distance(sentence1, sentence2, tf1, tf2, idf_metrics)\n",
    "\n",
    "                if matrix[row, col] > threshold:\n",
    "                    matrix[row, col] = 1.0\n",
    "                    degrees[row] += 1\n",
    "                else:\n",
    "                    matrix[row, col] = 0\n",
    "\n",
    "        for row in range(sentences_count):\n",
    "            for col in range(sentences_count):\n",
    "                if degrees[row] == 0:\n",
    "                    degrees[row] = 1\n",
    "\n",
    "                matrix[row][col] = matrix[row][col] / degrees[row]\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    #@staticmethod\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def power_method(matrix, epsilon):\n",
    "        transposed_matrix = matrix.T\n",
    "        sentences_count = len(matrix)\n",
    "        p_vector = numpy.array([1.0 / sentences_count] * sentences_count)\n",
    "        lambda_val = 1.0\n",
    "\n",
    "        while lambda_val > epsilon:\n",
    "            next_p = numpy.dot(transposed_matrix, p_vector)\n",
    "            lambda_val = numpy.linalg.norm(numpy.subtract(next_p, p_vector))\n",
    "            p_vector = next_p\n",
    "\n",
    "        return p_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##ALTERAR AQUI\n",
    "\n",
    "def compute_distance(sentence1, sentence2, tf1, tf2, idf_metrics):\n",
    "    # RETURN METODO_WIVES_AQUI()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    common_words = frozenset(sentence1) & frozenset(sentence2)\n",
    "\n",
    "    numerator = 0.0\n",
    "    for term in common_words:\n",
    "        numerator += tf1[term]*tf2[term] * idf_metrics[term]**2\n",
    "\n",
    "    denominator1 = sum((tf1[t]*idf_metrics[t])**2 for t in sentence1)\n",
    "    denominator2 = sum((tf2[t]*idf_metrics[t])**2 for t in sentence2)\n",
    "\n",
    "    if denominator1 > 0 and denominator2 > 0:\n",
    "        return numerator / (math.sqrt(denominator1) * math.sqrt(denominator2))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x10b472c80>\n",
      "0.0333333333333#&O início de Batman Vs Superman - A Origem da Justiça é promissor.\n",
      "0.0399122807018#&Batman Vs Superman - A Origem da Justiça - FotoA bem da verdade, há muito de conceitual em torno dos maiores super-heróis da DC Comics, pela primeira vez reunidos no cinema.\n",
      "0.0328947368421#&Se o Superman de Henry Cavill assume de vez a aura de símbolo da pureza, que precisa lidar com o mal sempre tentando corrompê-lo, o Batman de Ben Affleck traz ecos da histórica saga dos quadrinhos \"O Cavaleiro das Trevas\".\n",
      "0.0372807017544#&Só que Zack Snyder não é - e nunca foi - um diretor afeito a desenvolver narrativas.\n",
      "0.0333333333333#&Batman Vs Superman - A Origem da Justiça - FotoHá também o Lex Luthor de Jesse Eisenberg.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "\n",
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 5\n",
    "\n",
    "\n",
    "parser = PlaintextParser.from_file(\"critica.txt\", Tokenizer(LANGUAGE))\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "summarizer = BetaSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
